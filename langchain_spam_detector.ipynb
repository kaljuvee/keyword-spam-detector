{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abe79bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "LLM Spam Detector\n",
    "\n",
    "A simplified spam detector that uses Anthropic's Claude via LangChain to detect keyword spamming\n",
    "in e-commerce product descriptions.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea88afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Dict, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c4fcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangChain and Anthropic\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41d2549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scikit-learn metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bdef8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c9053e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnthropicSpamDetector:\n",
    "    \"\"\"Spam detector using Anthropic's Claude with LangChain and few-shot learning.\"\"\"\n",
    "    \n",
    "    def __init__(self, model: str = \"claude-3-sonnet-20240229\"):\n",
    "        # Initialize Anthropic client via LangChain\n",
    "        self.llm = ChatAnthropic(\n",
    "            model=model,\n",
    "            anthropic_api_key=os.getenv(\"ANTHROPIC_API_KEY\"),\n",
    "            temperature=0.1\n",
    "        )\n",
    "        \n",
    "        self.system_prompt = \"\"\"\n",
    "        You are an expert at detecting keyword spam in e-commerce product descriptions.\n",
    "        \n",
    "        Keyword spamming is when sellers include unrelated, irrelevant keywords in their product descriptions\n",
    "        to improve their ranking in search results. This creates a poor experience for buyers who see irrelevant\n",
    "        products in their search results.\n",
    "        \n",
    "        Examples of keyword spam:\n",
    "        1. Adding a list of brand names that aren't related to the actual product\n",
    "        2. Adding hashtags with irrelevant terms\n",
    "        3. Including phrases like \"ignore:\" followed by keywords\n",
    "        4. Adding a long list of unrelated terms at the end of a description\n",
    "        \n",
    "        Your task is to analyze product descriptions and determine if they contain keyword spam.\n",
    "        Respond with a JSON object containing:\n",
    "        1. \"is_spam\": boolean indicating if the description contains keyword spam\n",
    "        2. \"spam_score\": a number between 0 and 1 indicating the confidence level\n",
    "        3. \"reasoning\": brief explanation of your decision\n",
    "        \"\"\"\n",
    "        \n",
    "        # Few-shot examples for better performance\n",
    "        self.few_shot_examples = [\n",
    "            {\n",
    "                \"description\": \"Super cute high waisted blue jeans. recommended for shorter / petite girls, I'm 5'1 and it fits me perfect. These are more of jeggings than jeans and have a polyester material inside. Only flaw: the zipper goes down by itself sometimes. Size 0 / waist 23\",\n",
    "                \"label\": \"Not Spam\"\n",
    "            },\n",
    "            {\n",
    "                \"description\": \"Jordan 5 P51 Camo Size 9 Good condition Soles have yellowing No box or lacelocks $160 Travis Supreme concepts Jordan 1 3 5 6 7 11 12 Nike ovo Kanye yeezy boost 350 shadow royal bred shattered cement top 3 black toe infrared raptor gamma space jam air max vapormax flyknit Travis Scott kaws off white atmos 95 97 98 silver gold bullet protro Kobe fieg kith Levi's undefeated Palace tinker stash SB dunk stone island Foamposite plus Acronym VF Wotherspoon 270 SW LeBron Kyrie Pippen\",\n",
    "                \"label\": \"Spam\"\n",
    "            },\n",
    "            {\n",
    "                \"description\": \"Denim jacket Never been worn Size XL\",\n",
    "                \"label\": \"Not Spam\"\n",
    "            },\n",
    "            {\n",
    "                \"description\": \"gorgeous y2k juicy couture velvet zip up. super pretty turquoise color. worn only a few times and in perfect condition. 100% authentic! size medium but would fit a small nicely tags #lingerie #lace #vintagedepop #sofuckingdepop #depopfamous lily rose depp devon lee carlson corset black tank cami 90s 2000s y2k tank top camisole black lace top mock lingerie black v neck lace lined top strappy top carrie bradshaw milkmaid cami crop top blouse v neck lace sex and the city cruel intentions clueless black swan victorias secret cami\",\n",
    "                \"label\": \"Spam\"\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        # Create LangChain prompt template\n",
    "        self.prompt_template = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", self.system_prompt),\n",
    "            (\"human\", \"{user_content}\")\n",
    "        ])\n",
    "        \n",
    "        # Create LangChain chain with JSON output parser\n",
    "        self.chain = self.prompt_template | self.llm | StrOutputParser()\n",
    "    \n",
    "    def predict(self, texts: List[str], batch_size: int = 5) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Predict if texts contain spam using Anthropic's Claude with LangChain.\n",
    "        \n",
    "        Args:\n",
    "            texts: List of text strings\n",
    "            batch_size: Number of examples to process in each API call\n",
    "            \n",
    "        Returns:\n",
    "            List of dictionaries with prediction results\n",
    "        \"\"\"\n",
    "        results = []\n",
    "        \n",
    "        # Process in batches to avoid token limits\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch_texts = texts[i:i+batch_size]\n",
    "            batch_results = self._predict_batch(batch_texts)\n",
    "            results.extend(batch_results)\n",
    "            \n",
    "        return results\n",
    "    \n",
    "    def _predict_batch(self, texts: List[str]) -> List[Dict]:\n",
    "        \"\"\"Process a batch of texts with the Anthropic API via LangChain.\"\"\"\n",
    "        batch_results = []\n",
    "        \n",
    "        # Create few-shot examples content\n",
    "        few_shot_content = \"\\n\\n\".join([\n",
    "            f\"Description: {example['description']}\\nLabel: {example['label']}\"\n",
    "            for example in self.few_shot_examples\n",
    "        ])\n",
    "        \n",
    "        for text in texts:\n",
    "            try:\n",
    "                # Create prompt with few-shot examples\n",
    "                user_content = f\"\"\"\n",
    "                Here are some examples of spam and non-spam product descriptions:\n",
    "                \n",
    "                {few_shot_content}\n",
    "                \n",
    "                Now, analyze this product description for keyword spam:\n",
    "                \n",
    "                Description: {text}\n",
    "                \n",
    "                Respond with a JSON object containing:\n",
    "                1. \"is_spam\": boolean indicating if the description contains keyword spam\n",
    "                2. \"spam_score\": a number between 0 and 1 indicating the confidence level\n",
    "                3. \"reasoning\": brief explanation of your decision\n",
    "                \"\"\"\n",
    "                \n",
    "                # Invoke the LangChain chain\n",
    "                response = self.chain.invoke({\"user_content\": user_content})\n",
    "                \n",
    "                # Parse JSON response\n",
    "                # Find JSON object in the response (Claude sometimes adds extra text)\n",
    "                json_start = response.find('{')\n",
    "                json_end = response.rfind('}') + 1\n",
    "                if json_start >= 0 and json_end > json_start:\n",
    "                    json_str = response[json_start:json_end]\n",
    "                    result = json.loads(json_str)\n",
    "                else:\n",
    "                    # Fallback if no JSON found\n",
    "                    result = {\n",
    "                        \"is_spam\": \"spam\" in response.lower(),\n",
    "                        \"spam_score\": 0.5 if \"spam\" in response.lower() else 0.0,\n",
    "                        \"reasoning\": \"Failed to parse JSON response\"\n",
    "                    }\n",
    "                \n",
    "                batch_results.append(result)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error with Anthropic API: {e}\")\n",
    "                # Fallback result\n",
    "                batch_results.append({\n",
    "                    \"is_spam\": False,\n",
    "                    \"spam_score\": 0.0,\n",
    "                    \"reasoning\": f\"Error processing with LLM: {str(e)}\"\n",
    "                })\n",
    "        \n",
    "        return batch_results\n",
    "    \n",
    "    def predict_binary(self, texts: List[str]) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Make binary predictions (spam/not spam).\n",
    "        \n",
    "        Args:\n",
    "            texts: List of text strings\n",
    "            \n",
    "        Returns:\n",
    "            Array of binary predictions (0 for non-spam, 1 for spam)\n",
    "        \"\"\"\n",
    "        results = self.predict(texts)\n",
    "        return np.array([1 if result.get(\"is_spam\", False) else 0 for result in results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685a565f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path: str) -> Tuple[List[str], List[int]]:\n",
    "    \"\"\"\n",
    "    Load data from CSV file.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to CSV file\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (descriptions, labels)\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    return df['description'].tolist(), df['label'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240c8cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_true: List[int], y_pred: List[int]) -> Dict:\n",
    "    \"\"\"\n",
    "    Evaluate model performance using scikit-learn metrics.\n",
    "    \n",
    "    Args:\n",
    "        y_true: True labels\n",
    "        y_pred: Predicted labels\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with evaluation metrics\n",
    "    \"\"\"\n",
    "    # Calculate metrics using scikit-learn\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "    \n",
    "    # Calculate confusion matrix using scikit-learn\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    print(\"\\nAnthropic Claude Results:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision (Spam): {precision:.4f}\")\n",
    "    print(f\"Recall (Spam): {recall:.4f}\")\n",
    "    print(f\"F1-Score (Spam): {f1:.4f}\")\n",
    "    \n",
    "    # Print confusion matrix\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(\"                 Predicted\")\n",
    "    print(\"                 Not Spam    Spam\")\n",
    "    print(f\"Actual Not Spam    {cm[0][0]}         {cm[0][1]}\")\n",
    "    print(f\"      Spam         {cm[1][0]}         {cm[1][1]}\")\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'confusion_matrix': cm.tolist()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf38057d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Main function to run the LLM spam detection.\"\"\"\n",
    "    print(\"Loading data...\")\n",
    "    # Load a small subset of test data to save API costs\n",
    "    test_texts, test_labels = load_data('data/test_set.csv')\n",
    "    \n",
    "    # Use a smaller subset for testing\n",
    "    test_subset_size = min(20, len(test_texts))\n",
    "    test_subset_texts = test_texts[:test_subset_size]\n",
    "    test_subset_labels = test_labels[:test_subset_size]\n",
    "    \n",
    "    print(f\"Testing on {test_subset_size} examples from test data\")\n",
    "    \n",
    "    # Anthropic model\n",
    "    print(\"\\nEvaluating Anthropic Claude model...\")\n",
    "    anthropic_detector = AnthropicSpamDetector()\n",
    "    anthropic_predictions = anthropic_detector.predict_binary(test_subset_texts)\n",
    "    \n",
    "    # Print detailed results\n",
    "    print(\"\\nDetailed Results:\")\n",
    "    print(f\"{'#':<3} {'Actual':<8} {'Predicted':<10} {'Description':<50}\")\n",
    "    print(\"-\" * 75)\n",
    "    \n",
    "    for i, (text, true_label, pred_label) in enumerate(zip(test_subset_texts, test_subset_labels, anthropic_predictions)):\n",
    "        # Truncate text for display\n",
    "        short_text = text[:47] + \"...\" if len(text) > 50 else text\n",
    "        print(f\"{i+1:<3} {'Spam' if true_label == 1 else 'Not Spam':<8} {'Spam' if pred_label == 1 else 'Not Spam':<10} {short_text:<50}\")\n",
    "    \n",
    "    # Evaluate model\n",
    "    metrics = evaluate_model(test_subset_labels, anthropic_predictions)\n",
    "    \n",
    "    print(\"\\nNote: Anthropic Claude model was evaluated on a small subset of the test data to save API costs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033204fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main() "
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "executable": "/usr/bin/env python3",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
